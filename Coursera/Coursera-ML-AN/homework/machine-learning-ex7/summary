本次大作业旨在加深我们对K-means算法和PCA的认识和理解。
第一部分主要是让我们实现K聚类中心随机初始化、簇分配和聚类中心重置三个过程。
一般我们设置一个迭代次数然后迭代就行。
然后是K-means算法用于降维压缩图片的例子。
本例子中，一个图片每个像素由24bit组成，是典型的RGB结构，这样的话一个128*128的图片就要128*128*24的存储空间，30多万非常大。
我们的方法是，用K-means找到16个能最好的将256*256*256划分成16个区域的聚类中心，也就是说将每个像素颜色的24bit压缩成4bit，最后存储空间只有6万多，压缩近五倍空间。
方法很简单，带进模型跑一遍就行了。
不过存储空间实质是16*24+128*128*4，因为那16种颜色需要用24bit来说明是哪一种，相当于map映射吧。
衡量哪个随机初始化的K-means得到的聚类效果最好，可以用失真误差那条同时来计算，也就是1/m连加x-x所属聚类的模的平方。

而pca也是用一个图像压缩的例子让我们直观的感受pca的作用和丢失的信息。
pca的关键在于找到合适的能保存最多信息的维度，以及坐标映射，还有协方差矩阵的运算，特征值特征向量的理解，
特征向量抓取了整个矩阵最重要的几个方向，也就是说提供了提取最重要的几个特征的方法。
衡量pca的指标可以用前k个特征值的和除以所有特征值和所得到的百分比。

K-means算法并不会降维，其之所以压缩图片，是因为他把每个像素点的存储空间减少了，比如说从24减少为4.
而pca则是降维了，比如说他从1024个像素的图片提取主要成分，最后可能只剩下100个像素，然后再用这100个像素去还原图片，讲道理非常失真。也就是由原来的32*32变成10*10.

